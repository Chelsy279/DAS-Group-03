---
title: "Analysis of Factors Influencing Philippine Family Population Based on GLM"
author: "Group_03"
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: 
    include-in-header: 
      text: |
        \usepackage{booktabs}
        \usepackage{float}
        \floatplacement{table}{H}
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
---

```{r}
library(ggplot2)
library(GGally)
library(tidyverse)
library(dplyr)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(ggcorrplot)
```

# Introduction

In Philippine, **FIES**(Family Income and Expenditure Survey), which is undertaken every three years, is aimed at providing data on family income and expenditure. This dataset, comes from the FIES recorded in the Philippines, is analysed in this report.

In particular, this report presents numerical and graphical summaries of FIES and fits a **Generalized Linear Model(GLM)** to analyze which household related variables influence the number of people living in a household.

# Research Question

Which household related variables influence the number of people living in a household?

# Data Cleaning

First read the data and tidy the data using tidyverse:

```{r}
#| echo: true
# Read the data set
Data_FIES <- read.csv("dataset03.csv")
# Tidy the data
FIES <- Data_FIES %>%
  # Place the dependent variable in the first column and delete the unique value
  select(Total.Number.of.Family.members, everything(), -Region) %>%
  # Convert categorical variables into factors
  mutate(
    Household.Head.Sex = as.factor(Household.Head.Sex),
    Type.of.Household = as.factor(Type.of.Household),
    Electricity = as.factor(Electricity)) %>%
  # Remove Missing Values
  drop_na()
FIES_saved <- FIES # Used for model fitting
```

We moved the implicit variable to the first row and deleted the region which has no difference in the data. 'Household.Head.Sex', 'Type.of.Household', and 'Electricity' were converted to factors to ensure that the statistical model correctly handled the categorical variables. Also we removed missing values to ensure data integrity.

The dependent variable and independent variables are shown as below:

**Dependent Variable**:

-   **Total.Number.of.Family.members**: Number of people living in the house.

**Independent Variables**:

-   **Total.Household.Income**: Annual household income (in Philippine peso)

-   **Total.Food.Expenditure**: Annual expenditure by the household on food (in Philippine peso)

-   **Household.Head.Sex**: Head of the households sex

-   **Household.Head.Age**: Head of the households age (in years)

-   **Type.of.Household**: Relationship between the group of people living in the house

-   **House.Floor.Area**: Floor area of the house (in $m^2$)

-   **House.Age**: Age of the building (in years)

-   **Number.of.bedrooms**: Number of bedrooms in the house

-   **Electricity**: Does the house have electricity? (1=Yes, 0=No)

# Exploratory Data Analysis

Then we can check the data structure and get summary statistics of all variables:

```{r}
#| echo: true
str(FIES) # Check data structure 
summary(FIES) # Get summary statistics of all variables  
dim(FIES) # Check dataset dimensions (number of rows and columns)
```

## Numerical summaries and Data visualization

Now we can take a look at the numerical summaries and data visualization of **dependent variable** shown in the following tables and plots:

```{r, tab.cap="H"}
#| label: tbl-y
#| tbl-cap: Summary statistics for 'Total.Number.of.Family.members'
#| tbl-cap-location: top

FIES |>
  summarize('Mean' = mean(Total.Number.of.Family.members),
            'Median' = median(Total.Number.of.Family.members),
            'St.Dev' = sd(Total.Number.of.Family.members),
            'Min' = min(Total.Number.of.Family.members),
            'Max' = max(Total.Number.of.Family.members),
            'IQR' = quantile(Total.Number.of.Family.members,0.75)-quantile(Total.Number.of.Family.members,0.25),
            'Sample_size' = n()
  ) |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  ) 

```

```{r, fig.pos="H"}
#| label: fig-y
#| fig-cap: Histogram of 'Total.Number.of.Family.members'

# Visualize dependent variable distribution
ggplot(FIES, aes(x = Total.Number.of.Family.members)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(x = "Number of Family Members", y = "Frequency")

```

From @tbl-y, we can see our dataset includes 1887 samples, which is a sufficiently large sample size to ensure reliability. The mean value (4.68) and median (4.00) are very close, suggesting a roughly symmetric distribution. However, the median is slightly lower than the mean hints at a mild right skew in the data. The standard deviation (2.30) indicates moderate variability around the mean.

@fig-y shows a strong right-skewed distribution of frequency data. The highest bar (around 300) is concentrated on the left side of the x-axis, indicating that most values are in the lower ranges. The frequency sharply decreased toward the right, with the far-right bars approaching 0, shows that rare occurrences in higher-value intervals.

Then check the variance of the dependent variable and compare with the mean:

```{r}
mean <- mean(FIES$Total.Number.of.Family.members)
var <- var(FIES$Total.Number.of.Family.members)
var_ratio <- var/mean
cat("mean =",mean,"\n")
cat("var =",var,"\n")
cat("var_ratio =",var_ratio,"\n")
```

var/mean=5.28/4.68=1.13 $\approx$ 1 indicates that there is no overdispersion problem, so Poisson regression model may be appropriate.

Then we separate independent variables into categorical variables and numerical variables for analysis.

1.  **Categorical Variables**

```{r, tab.cap="H"}
#| label: tbl-y-sex
#| tbl-cap: Summary statistics on 'Total.Number.of.Family.members' by 'Household.Head.Sex' 
#| tbl-cap-location: top

FIES |>
  summarize('Mean' = mean(Total.Number.of.Family.members),
            'Median' = median(Total.Number.of.Family.members),
            'St.Dev' = sd(Total.Number.of.Family.members),
            'Min' = min(Total.Number.of.Family.members),
            'Max' = max(Total.Number.of.Family.members),
            'IQR' = quantile(Total.Number.of.Family.members,0.75)-quantile(Total.Number.of.Family.members,0.25),
            'Sample_size' = n(),
            .by = Household.Head.Sex) |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )

```

```{r, fig.pos="H"}
#| label: fig-y-sex
#| fig-cap: Boxplot of 'Total.Number.of.Family.members' by 'Household.Head.Sex'

ggplot(FIES, aes(x = Household.Head.Sex, y = Total.Number.of.Family.members, fill = Household.Head.Sex)) +
  geom_boxplot() +
  scale_fill_manual(values = c("tomato","steelblue")) + 
  labs(x = "Household Head's Gender", y = "Family Size") 

```

@tbl-y-sex compares family size statistics between female-headed and male-headed households. Female-headed households exhibit smaller family size, with a mean of 3.83 and a median of 3.00, while male-headed households show significantly larger families (mean = 4.91, median = 5.00). Despite similar variability in both groups (standard deviations of nearly 2.3), the male-headed households display a broader range. Notably, the dataset is heavily skewed toward male-headed households (1487 samples vs. 400 female samples), which could influence the result. Both groups share identical interquartile ranges (IQR = 3.00), suggesting comparable central clustering of data.

@fig-y-sex shows that male-headed households exhibit a higher median family size of 5 members, compared to female-headed households with a median of 4 members. Both groups shows moderate variability in their distribution, but male-headed families display a wider range, with extreme outliers reaching up to 16 members which higher than the maximum of 15 members observed in female-headed households. This visualizes the tendency for male-led families to hold a larger household size.

```{r, tab.cap="H"}
#| label: tbl-y-household
#| tbl-cap: Summary statistics on 'Total.Number.of.Family.members' by 'Type.of.Household' 
#| tbl-cap-location: top

FIES |>
  summarize('Mean' = mean(Total.Number.of.Family.members),
            'Median' = median(Total.Number.of.Family.members),
            'St.Dev' = sd(Total.Number.of.Family.members),
            'Min' = min(Total.Number.of.Family.members),
            'Max' = max(Total.Number.of.Family.members),
            'IQR' = quantile(Total.Number.of.Family.members,0.75)-quantile(Total.Number.of.Family.members,0.25),
            'Sample_size' = n(),
            .by = Type.of.Household) |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )

```

```{r, fig.pos="H"}
#| label: fig-y-household
#| fig-cap: Boxplot of 'Total.Number.of.Family.members' by 'Type.of.Household'

ggplot(FIES, aes(x = Type.of.Household, y = Total.Number.of.Family.members, fill = Type.of.Household)) +
  geom_boxplot() +
  scale_fill_manual(values = c("gold","tomato","steelblue")) + 
  labs(x = "Household Type", y = "Family Size") 
```

@tbl-y-household summarizes family size statistics across three household types. Single-family households have the smallest average family size (mean = 4.14, median = 4.00) with a large sample size (1311). Extended families show significantly larger family sizes (mean=5.88, median = 5.00) and a broader spread (max = 16). Households with two or more unrelated members report the highest average (mean = 6.89, median - 6.00), but with a extremely small sample size (9) weakens reliability.

@fig-y-household shows that extended families exhibit the highest median family size (5) with a broader range which is up to 16 members, indicating potential outliers. Single families shows a lower median (4) and tighter clustering of data. It reflects a more consistent household size. Households with two or more unrelated members have a median of 6 members. However it only have a sample size of 9 which weakens the reliability of this category.

```{r, tab.cap="H"}
#| label: tbl-y-electricity
#| tbl-cap: Summary statistics on 'Total.Number.of.Family.members' by 'Electricity' 
#| tbl-cap-location: top

FIES |>
  summarize('Mean' = mean(Total.Number.of.Family.members),
            'Median' = median(Total.Number.of.Family.members),
            'St.Dev' = sd(Total.Number.of.Family.members),
            'Min' = min(Total.Number.of.Family.members),
            'Max' = max(Total.Number.of.Family.members),
            'IQR' = quantile(Total.Number.of.Family.members,0.75)-quantile(Total.Number.of.Family.members,0.25),
            'Sample_size' = n(),
            .by = Electricity) |>
  gt() |>
  fmt_number(decimals=2) |>
  cols_label(
    Mean = html("Mean"),
    Median = html("Median"),
    St.Dev = html("Std. Dev"),
    Min = html("Minimum"),
    Max = html("Maximum"),
    IQR = html("Interquartile Range"),
    Sample_size = html("Sample Size")
  )

```

```{r, fig.pos="H"}
#| label: fig-y-electricity
#| fig-cap: Boxplot of 'Total.Number.of.Family.members' by 'Electricity'

ggplot(FIES, aes(x = Electricity, y = Total.Number.of.Family.members, fill = Electricity)) +
  geom_boxplot() +
  scale_fill_manual(values = c("tomato","steelblue")) + 
  labs(x = "Electricity (0 = No, 1 = Yes)", y = "Family Size") 

```

From @tbl-y-electricity, we can see households with electricity (1,630) are about six times more than those without (257). The mean values are nearly identical (4.70 vs. 4.67), but the median is slightly higher for households without electricity (5.00 vs. 4.00). The standard deviation is also slightly larger in the non-electric group (2.47 vs. 2.27), indicating a bit more variability. The maximum value is higher in the electricity group (16.00 vs. 12.00), suggesting a wider range. Both groups have the same interquartile range (3.00), meaning their middle 50% distributions are similar. These differences can be visualized more clearly with boxplots.

@fig-y-electricity shows that households without electricity tend to have a slightly larger median family size compared to those with electricity. However, the distributions of family sizes in both groups are quite similar. The spread of family sizes in both groups is also comparable, as indicated by the interquartile range. Additionally, both groups exhibit several outliers, representing families with unusually large sizes, as shown by the points beyond the "whiskers" of the boxplots.

2.  **Numerical Variables**

```{r, fig.pos="H"}
#| label: fig-his-num
#| fig-cap: Histograms for Numerical Variables

p1 <- ggplot(FIES, aes(x = Total.Household.Income)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "Household Income Distribution", x = "Household Income", y = "Count")
p2 <- ggplot(FIES, aes(x = Total.Food.Expenditure)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "Household Expenditure Distribution", x = "Household Expenditure", y = "Count")
p3 <- ggplot(FIES, aes(x = Household.Head.Age)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "Household Head Age Distribution", x = "Household Head Age", y = "Count")
p4 <- ggplot(FIES, aes(x = House.Floor.Area)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "House Floor Area Distribution", x = "House Floor Area", y = "Count")
p5 <- ggplot(FIES, aes(x = House.Age)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "House Age Distribution", x = "House Age", y = "Count")
p6 <- ggplot(FIES, aes(x = Number.of.bedrooms)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +
  labs(title = "Number of bedrooms Distribution", x = "Number of bedrooms", y = "Count")
(p1 | p2 | p3) / (p4 | p5 | p6)
```

From @fig-his-num, we can see the distributions of 'Total.Household.Income', 'Total.Food.Expenditure', 'House.Floor.Area' and 'House.Age' are right-skewed, so applying a log transformation would be beneficial when fitting a Poisson model.

'Household.Head.Age' follows an approximately normal distribution, so no transformation will be applied to this variable in modeling process. Most household heads falling within the 30-60 age range. This suggests that middle-aged individuals are the primary decision-makers in households.

The 'Number.of.bedrooms' is a discrete variable, with most houses having 2 or 3 bed rooms, while houses with 4 or more bedrooms are less common. 

So we can covert the 'Number.of.bedrooms' into categorical variable:

```{r}
#| echo: true
# Convert 'Number.of.bedrooms' to categorical variable
FIES$Bedroom.Category <- cut(FIES$Number.of.bedrooms, 
         c(-1, 1, 3, Inf), 
         labels = c("Small", "Medium", "Large"),right = TRUE)
# Convert categorical variable into factor
FIES$Bedroom.Category <- factor(FIES$Bedroom.Category)
```

Then we can use the heat map to check the correlation between numerical variables and dependent variable:

```{r, fig.pos="H"}
#| label: fig-corr-num
#| fig-cap: Heat map for numerical variables by 'Total.Number.of.Family.members' 

# Select all numerical variables
numeric_vars <- FIES[, sapply(FIES, is.numeric)]
# Since our dependent variable is a count varaible, use Spearman method
cor_matrix <- cor(numeric_vars, method = "spearman")
# Plot the correlation heatmap
ggcorrplot(cor_matrix, type = "full", lab = TRUE, lab_size = 4, 
           colors = c("blue", "white", "red"), outline.color = "black", 
           legend.title = "Correlation") +
  labs(title = "Correlation Matrix for Numeric Variables") +
  theme(
    axis.text.x = element_text(size = 9, angle = 45, vjust = 1, hjust = 1),
    axis.text.y = element_text(size = 9),
    legend.text = element_text(size = 14),
    legend.title = element_text(size = 16)
  )
```

Form @fig-corr-num, we can see there is a strong correlation between 'Total.Household.Income' and 'Total.Food.Expenditure'. We will address this issue in the subsequent modeling process. 'Total.Number.of.Family.Members' shows a strong correlation with 'Total.Food.Expenditure', while 'Household.Head.Age' and 'House.Age' have a slight negative correlation with 'Total.Number.of.Family.Members'.

There is also some correlation between 'Total.Household.Income' and 'Number.of.bedrooms', 'Total.Household.Income' and 'House.Floor.Area', 'Total.Food.Expenditure' and 'Number.of.bedrooms', and 'House.Floor.Area' and 'Number.of.bedrooms'.

# Formal Data Analysis

Since the dependent variable 'Total.Number.of.Family.members' is a typical count variable with a mean and variance that are approximately equal, Poisson regression was chosen for modeling. Based on the results of EDA, some variables were log-transformed to improve linear relationships and reduce heteroscedasticity. All selected variables were then included in the model, and stepwise regression using drop1(poisson_model, test = "F") was performed to assess variable significance, gradually eliminating insignificant variables to ensure the final model's robustness and explanatory power.

```{r}
FIES <- FIES_saved
colnames(FIES) <- c("Family_Size", "Income", "Food_Exp", "Head_Sex", "Head_Age","Household_Type", "Floor_Area", "House_Age", "Bedrooms", "Electricity")
```

Fit the first Poisson regression model:
(Add fomula1)
```{r}
poisson_model1 <- glm(Family_Size ~ 
                       log(Income) +
                       log(Food_Exp) +
                       Head_Sex +
                       Head_Age + 
                       Household_Type +
                       log(Floor_Area) +
                       log(House_Age+0.1) +
                       Bedrooms +
                       Electricity, 
                     family = poisson(link = "log"),
                     data = FIES)

summary(poisson_model1)
drop1(poisson_model1, test = "F")
```

For Floor_Area, since it is a continuous variable, a log transformation was applied during the EDA process to improve linearity and reduce heteroscedasticity. However, it remained insignificant in the Poisson regression model even after transformation, so it is considered for removal. As for Bedrooms, it is a discrete integer variable with a large number of zero values. Given the potential categorical effect, converting it into a categorical variable may be more appropriate to better capture its impact on family size.

```{r}
#| echo: true
FIES$Bedroom.Category <- cut(FIES$Bedrooms, 
                             breaks = c(-1, 1, 3, Inf), 
                             labels = c("Small", "Medium", "Large"),
                             right = TRUE)
FIES$Bedroom.Category <- factor(FIES$Bedroom.Category)
```

Fit a linear regression model with 'Bedroom.Category'
```{r}
model_cat <- lm(Family_Size ~ Bedroom.Category, data = FIES)
summary(model_cat)
```

Fit a poisson regression model with 'Bedroom.Category'
```{r}
poisson_model_cat <- glm(Family_Size ~ 
                       log(Income) +
                       log(Food_Exp) +
                       Head_Sex +
                       Head_Age + 
                       Household_Type +
                       log(House_Age+1) +
                       Bedroom.Category +
                       Electricity, 
                     family = poisson(link = "log"),
                     data = FIES)

summary(poisson_model_cat)
drop1(poisson_model_cat, test = "F")
```

After converting Bedrooms into a categorical variable and refitting the model, it remained insignificant, so it was ultimately removed.

Fit the second Poisson regression model:
(Add fomula2)
```{r}
poisson_model2 <- glm(Family_Size ~ 
                          log(Income) +
                          log(Food_Exp) +
                          Head_Sex +
                          Head_Age + 
                          Household_Type +
                          log(House_Age+1) +
                          Electricity, 
                        family = poisson(link = "log"),
                        data = FIES)
summary(poisson_model2)
```

Although the classification of Household_Type is not significant statistically, it is retained based on the theoretical justification from the original data classification. This ensures that its impact is still considered during model interpretation.

```{r, fig.pos="H"}
#| label: fig-residual
#| fig-cap: The Pearson and deviance residuals against the linear predictor

resp<-resid(poisson_model2,type= "pearson")
resd<-resid(poisson_model2,type= "deviance")
p1 <- ggplot(data.frame(sample = resp), aes(sample = sample)) +
  geom_point(stat = "qq", color = "steelblue") +
  ylab("Pearson Residuals")
p2 <- ggplot(data.frame(sample = resd), aes(sample = sample)) +
  geom_point(stat = "qq", color = "steelblue") +
  ylab("Deviance Residuals")
p3 <- ggplot(poisson_model2, aes(x = log(fitted(poisson_model2)), y = residuals(poisson_model2, type = "pearson"))) +
  geom_jitter(color = "tomato",width = 0.5, height = 0.5) +
  geom_abline(slope = 0, intercept = 0, col = "steelblue", linewidth = 1) +
  ylab("Pearson Residuals") + xlab(expression(hat(mu)))
grid.arrange(arrangeGrob(p1, p2, ncol = 1), p3, ncol = 2)
```

By plotting the QQ plots of Pearson and Deviance, we found that the data conform to the normality assumption. To further assess whether there is significant overdispersion in the Deviance distribution, we compared the performance of the original Poisson model and the Quasi-Poisson model in handling overdispersion. By comparing the standardized Pearson residuals of both models, we found that the original Poisson model performed better, indicating no significant overdispersion. Therefore, no adjustment was made to the standard errors of the parameters, as overdispersion was not evident.

```{r, fig.pos="H"}
#| label: fig-likelihood
#| fig-cap: Regular likelihood and Quasi-likelihood

X2 <- sum(resid(poisson_model2, type = "pearson")^2)
dp <- X2 / poisson_model2$df.res
summary(poisson_model2, dispersion = dp)
pred <- predict(poisson_model2, type = "response")
stand.resid <- rstandard(model = poisson_model2, type = "pearson") # Standardised Pearson residuals
par(mfrow=c(1,2))
plot(x = pred, y = stand.resid, xlab = "Predicted count", ylab = "Standardised Pearson residuals",
     main = "Regular likelihood", ylim = c(-5,5))
abline(h = c(-3,-2, 0, 2, 3), lty = "dotted", col = "red")

# Fit the third Poisson regression model
poisson_model3 <- glm(Family_Size ~ 
                        log(Income) +
                        log(Food_Exp) +
                        Head_Sex +
                        Head_Age + 
                        Household_Type +
                        log(House_Age+1) +
                        Electricity, 
                      family = quasipoisson(link = "log"),
                      data = FIES)  # Quasi-Poisson model
pred <- predict(poisson_model3, type = "response")
stand.resid <- rstandard(model = poisson_model3, type = "pearson") # Standardised Pearson residuals
plot(x = pred, y = stand.resid, xlab = "Predicted count", ylab = "Standardised Pearson residuals",
     main = "Quasi-likelihood", ylim = c(-5,5))
abline(h = c(-3,-2, 0, 2, 3), lty = "dotted", col = "red")
```

Based on the model comparison and LRT test results, and considering the high correlation observed in the EDA heatmap, an interaction term between Income and Food_Exp was introduced. After comparing the original model with the model including the interaction term, it was found that the Deviance decreased by 47.118 after adding the interaction term, indicating that the inclusion of the interaction term significantly improved the model's fit. Therefore, the conclusion can be made that introducing the interaction term effectively enhanced the model's explanatory power and fit.

Fit the fourth Poisson regression model with an interaction term:
```{r}
poisson_model4 <- glm(Family_Size ~ 
                      log(Income) * log(Food_Exp) +
                      Head_Sex + 
                      Head_Age + 
                      Household_Type +
                      log(House_Age + 1) +
                      Electricity, 
                      family = poisson(link = "log"),
                      data = FIES)
anova(poisson_model2, poisson_model4, test = "LRT")
```

```{r, fig.pos="H"}
#| label: fig-residual
#| fig-cap: The Pearson and deviance residuals against the linear predictor

resp<-resid(poisson_model4,type= "pearson")
resd<-resid(poisson_model4,type= "deviance")
p1 <- ggplot(data.frame(sample = resp), aes(sample = sample)) +
  geom_point(stat = "qq", color = "steelblue") +
  ylab("Pearson Residuals")
p2 <- ggplot(data.frame(sample = resd), aes(sample = sample)) +
  geom_point(stat = "qq", color = "steelblue") +
  ylab("Deviance Residuals")
p3 <- ggplot(poisson_model4, aes(x = log(fitted(poisson_model4)), y = residuals(poisson_model4, type = "pearson"))) +
  geom_jitter(color = "tomato",width = 0.5, height = 0.5) +
  geom_abline(slope = 0, intercept = 0, col = "steelblue", linewidth = 1) +
  ylab("Pearson Residuals") + xlab(expression(hat(mu)))
grid.arrange(arrangeGrob(p1, p2, ncol = 1), p3, ncol = 2)
```

The QQ plots of the Pearson and Deviance both conform to the normality assumption and there is no obvious overdispersion in the Residuals plot.

Then we can check the Relative Risk(RR):

```{r}
# Check the Relative Risk(RR)
exp(coef(poisson_model4)) 
# For Poission Regression, coefficients represent log-relative risk, so convert them to RR
```

(Add fomula4)

Based on the results of Relative Risk(RR), the following key conclusions can be summarized:

-   Income's Impact on Family Size: When income increases by 1%, the average family size increases by approximately 3.79 times. This indicates a positive correlation between income and family size, suggesting that higher income may be associated with larger families.

-   Food Expenditure's Impact on Family Size: When food expenditure increases by 1%, the average family size increases by approximately 11.25 times. This suggests that higher food spending is closely related to an increase in family size.

-   House Age's Impact on Family Size: When house age increases by 1%, the average family size decreases by approximately 5.39%. This implies that older houses may be associated with smaller family sizes, possibly due to living conditions or other factors.

-   Interaction Between Income and Food Expenditure: When both income and food expenditure increase by 1%, the average family size decreases by approximately 13.21%. This suggests that while both variables have a positive individual effect, their interaction shows a negative association, possibly indicating that higher income combined with higher food expenditure may not lead to a larger family size.

-   Head Sex's Impact on Family Size: Families with male heads tend to have approximately 15% more members than those with female heads. This indicates that families with male heads may be larger than those with female heads.

-   Head Age's Impact on Family Size: For each additional year in the head's age, the average family size decreases by approximately 0.4%. This suggests that older heads of households may have smaller families.

-   Household Type's Impact on Family Size: If the household type is a single-parent family, the average family size is about 25% smaller compared to other household types. Single-parent families generally have smaller family sizes.

# Conclusion

In conclusion, these results show that family size is closely related to various factors, particularly income, food expenditure, head sex, and household type. Changes in family size are influenced not only by individual variables but also by the interactions between them.
